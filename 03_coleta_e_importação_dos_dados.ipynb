{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Coleta e preparação dos dados referentes aos roubos de aparelhos celular em São Paulo no primeiro semestre de 2023"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Coleta"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Os dados que usaremos neste estudos foram coletados do site da Secretaria de Segurança Publica do governo de São Paulo. São dados públicos disponíveis em https://www.ssp.sp.gov.br/transparenciassp/Consulta.aspx. \n","\n","O site apresenta um conjunto de temas cujos quais podemos pesquisar por dados do nosso interesse. Ao selecionar um tema, no nosso caso, \"ROUBOS DE CELULAR\",  uma tabela de dados com segmentada pelos anos e seus respectivos meses é apresentada. Logo abaixo da tabela, temos dois botões: O primero permite que baixemos a \"METODOLOGIA\", um arquivo de texto contendo informações sobre os dados e um dicionário de dados. O segundo exporta os dados em um formato `xls` (Excel).\n","\n","Estou realizando a coleta em 08/2023, e destacaria três pontos de atenção para esta etapa:\n","\n","1. O download dos dados demoram um tempo relativamente alto. Alguns downloads levaram mais de 3 minutos sem nenhum outro recurso utilizando uma banda de 200 MB.\n","2. O servidor cai com frequência. Tive que recarregar a página várias vezes pois um erro 500 ocorria toda vez que tentava fazer downloads consecutivos. Por esta razão, por enquanto, preferi não programar um crawler para obter os dados. \n","3. Os dados vêm com um nome de arquivo inadequado: `DadosBO_2023_1(ROUBO DE CELULAR)`. Como o uso de parenteses espaços podem causar problemas, teremos que padronizar adequadamente o nome dos arquivos."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Preparação dos dados "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Importação dos dados"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Uma vez coletados os dados, a importação dos dados apresenta problemas:"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Se tentarmos importar um arquivo para um DataFrame pandas, o seguinte erro é levantado:"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Excel file format cannot be determined, you must specify an engine manually.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/raw/DadosBO_SP/DadosBO_2023_1(ROUBO DE CELULAR).xls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(file)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/excel/_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    477\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[1;32m    479\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[1;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/excel/_base.py:1500\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1497\u001b[0m         content_or_path\u001b[39m=\u001b[39mpath_or_buffer, storage_options\u001b[39m=\u001b[39mstorage_options\n\u001b[1;32m   1498\u001b[0m     )\n\u001b[1;32m   1499\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1501\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1502\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1503\u001b[0m         )\n\u001b[1;32m   1505\u001b[0m engine \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_option(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mio.excel.\u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m.reader\u001b[39m\u001b[39m\"\u001b[39m, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1506\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n","\u001b[0;31mValueError\u001b[0m: Excel file format cannot be determined, you must specify an engine manually."]}],"source":["file = \"data/raw/DadosBO_SP/DadosBO_2023_1(ROUBO DE CELULAR).xls\"\n","df_test = pd.read_excel(file)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Solucionado os problemas de importação"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["A exceção `ValueError: Excel file format cannot be determined, you must specify an engine manually` indica que formato do arquivo não pode ser determinado automaticamente. Essa exceção geralmente é lançada quando a `pandas` não consegue identificar o formato do arquivo do Excel. O erro também sugere que precisamos especificar manualmente o mecanismo (ou \"engine\") que o `pandas` deve usar para ler o arquivo do Excel. No nosso caso, como se trata de um arquivo `xls`, um modelo mais antigo da Microsoft, vamos utilizar a biblioteca `xlrd`, que é o padrão para este tipo de situação."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): done\n","Solving environment: done\n","\n","# All requested packages already installed.\n","\n"]}],"source":["!conda install xlrd -y"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Utilizando a engine `xlrd`, obtemos o seguinte erro:"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"XLRDError","evalue":"Unsupported format, or corrupt file: Expected BOF record; found b'A\\x00N\\x00O\\x00_\\x00'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(file, engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mxlrd\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/excel/_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    477\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[1;32m    479\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[1;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/excel/_base.py:1513\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[1;32m   1511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options \u001b[39m=\u001b[39m storage_options\n\u001b[0;32m-> 1513\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engines[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_io, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/excel/_xlrd.py:35\u001b[0m, in \u001b[0;36mXlrdReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m     33\u001b[0m err_msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInstall xlrd >= 2.0.1 for xls Excel support\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mxlrd\u001b[39m\u001b[39m\"\u001b[39m, extra\u001b[39m=\u001b[39merr_msg)\n\u001b[0;32m---> 35\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(filepath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/excel/_base.py:540\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbook \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_workbook(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandles\u001b[39m.\u001b[39;49mhandle)\n\u001b[1;32m    541\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    542\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/excel/_xlrd.py:48\u001b[0m, in \u001b[0;36mXlrdReader.load_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(filepath_or_buffer, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     47\u001b[0m     data \u001b[39m=\u001b[39m filepath_or_buffer\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m open_workbook(file_contents\u001b[39m=\u001b[39;49mdata)\n\u001b[1;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m open_workbook(filepath_or_buffer)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/xlrd/__init__.py:172\u001b[0m, in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m file_format \u001b[39mand\u001b[39;00m file_format \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    170\u001b[0m     \u001b[39mraise\u001b[39;00m XLRDError(FILE_FORMAT_DESCRIPTIONS[file_format]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m; not supported\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m bk \u001b[39m=\u001b[39m open_workbook_xls(\n\u001b[1;32m    173\u001b[0m     filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m    174\u001b[0m     logfile\u001b[39m=\u001b[39;49mlogfile,\n\u001b[1;32m    175\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[1;32m    176\u001b[0m     use_mmap\u001b[39m=\u001b[39;49muse_mmap,\n\u001b[1;32m    177\u001b[0m     file_contents\u001b[39m=\u001b[39;49mfile_contents,\n\u001b[1;32m    178\u001b[0m     encoding_override\u001b[39m=\u001b[39;49mencoding_override,\n\u001b[1;32m    179\u001b[0m     formatting_info\u001b[39m=\u001b[39;49mformatting_info,\n\u001b[1;32m    180\u001b[0m     on_demand\u001b[39m=\u001b[39;49mon_demand,\n\u001b[1;32m    181\u001b[0m     ragged_rows\u001b[39m=\u001b[39;49mragged_rows,\n\u001b[1;32m    182\u001b[0m     ignore_workbook_corruption\u001b[39m=\u001b[39;49mignore_workbook_corruption,\n\u001b[1;32m    183\u001b[0m )\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m bk\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/xlrd/book.py:79\u001b[0m, in \u001b[0;36mopen_workbook_xls\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[1;32m     77\u001b[0m t1 \u001b[39m=\u001b[39m perf_counter()\n\u001b[1;32m     78\u001b[0m bk\u001b[39m.\u001b[39mload_time_stage_1 \u001b[39m=\u001b[39m t1 \u001b[39m-\u001b[39m t0\n\u001b[0;32m---> 79\u001b[0m biff_version \u001b[39m=\u001b[39m bk\u001b[39m.\u001b[39;49mgetbof(XL_WORKBOOK_GLOBALS)\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m biff_version:\n\u001b[1;32m     81\u001b[0m     \u001b[39mraise\u001b[39;00m XLRDError(\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt determine file\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms BIFF version\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/xlrd/book.py:1284\u001b[0m, in \u001b[0;36mBook.getbof\u001b[0;34m(self, rqd_stream)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     bof_error(\u001b[39m'\u001b[39m\u001b[39mExpected BOF record; met end of file\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1283\u001b[0m \u001b[39mif\u001b[39;00m opcode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m bofcodes:\n\u001b[0;32m-> 1284\u001b[0m     bof_error(\u001b[39m'\u001b[39;49m\u001b[39mExpected BOF record; found \u001b[39;49m\u001b[39m%r\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmem[savpos:savpos\u001b[39m+\u001b[39;49m\u001b[39m8\u001b[39;49m])\n\u001b[1;32m   1285\u001b[0m length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget2bytes()\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m==\u001b[39m MY_EOF:\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/xlrd/book.py:1278\u001b[0m, in \u001b[0;36mBook.getbof.<locals>.bof_error\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbof_error\u001b[39m(msg):\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mraise\u001b[39;00m XLRDError(\u001b[39m'\u001b[39m\u001b[39mUnsupported format, or corrupt file: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m msg)\n","\u001b[0;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'A\\x00N\\x00O\\x00_\\x00'"]}],"source":["df_test = pd.read_excel(file, engine=\"xlrd\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["A exceção `XLRDError: Unsupported format, or corrupt file: Expected BOF record; found b'A\\x00N\\x00O\\x00_\\x00'` ocorreu porque o `xldr` esperava encontrar um registro de início de arquivo ([BOF - Beginning of File](https://learn.microsoft.com/en-us/openspecs/office_file_formats/ms-xls/4d6a3d1e-d7c5-405f-bbae-d01e9cb79366)), mas encontrou algo diferente, representado como a sequência de bytes `b'A\\x00N\\x00O\\x00_'`. Essa sequência de bytes pode ser uma pista para a natureza do problema, mas não é possível ter certeza sem mais contexto.\n","\n","Ocorre que BOF é um termo usado para se referir ao registro inicial que marca o início de arquivos. É uma sequência específica de bytes que marca o começo de um arquivo e ajuda os programas a entenderem como interpretar e processar o conteúdo do arquivo, seja ele binário ou em outro formato. No nosso caso, o `xldr` esperava encontrar o BOF de um arquivo binário `xls` da Microsoft, mas encontrou outra sequência de bytes; o que pode indicar que o arquivo não é um `xls` mas um outro formato."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Uma forma de descobrir o formato do arquivo é identificar seu MIMETYPE. O tipo [MIME (Multipurpose Internet Mail Extensions)](https://en.wikipedia.org/wiki/MIME) é uma convenção para especificar o tipo de conteúdo de um arquivo com base em sua natureza e formato. Embora o MIME tenha sido projetado principalmente para [SMTP (Simple Mail Transfer Protocol)](https://pt.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol), seus tipos de conteúdo também são importantes em outros protocolos de comunicação, como o [HTTP (HyperText Transfer Protocol)](https://pt.wikipedia.org/wiki/Hypertext_Transfer_Protocol), por exemplo. No HTTP para a web, os servidores inserem um campo de cabeçalho MIME no início de qualquer transmissão. Os clientes usam o tipo de conteúdo ou o cabeçalho do tipo de mídia para selecionar um aplicativo visualizador apropriado para o tipo de dados indicado.  \n","\n","Antes de tentar abrir o arquivo em um aplicativo externo, vamos tentar utilizar o comando [`file`](https://manned.org/file.1) do UNIX passando a opção `-i` para tentar obter uma descrição detalhada e precisa do formato incluindo o tipo MIME: \n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./data/raw/DadosBO_SP/DadosBO_2023_1(ROUBO DE CELULAR).xls: application/octet-stream; charset=binary\n"]}],"source":["!file -i ./data/raw/DadosBO_SP/DadosBO_2023_1\\(ROUBO\\ DE\\ CELULAR\\).xls"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["A saída não é animadora: `application/octet-stream; charset=binary` indica que o arquivo foi identificado como um fluxo de bytes genérico (application/octet-stream) e que não foi possível determinar um charset (conjunto de caracteres) específico. Em outras palavras, utilitário `file` não conseguiu identificar com precisão o formato específico do arquivo e o tratou como um fluxo genérico de bytes. A identificação específica do formato pode ser desafiadora quando não há informações claras nos primeiros bytes do arquivo ou quando o formato é ambíguo.\n","\n","Por esta razão, a alternativa mais rápida é tentar executá-lo em outra aplicação e observar como este aquivo é lido. As imagens abaixo mostram minha tentativa com LibreOffice:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","![pop-up](./img/2023-08-28_00-49.png)\n","![pop-up](./img/2023-08-28_00-54.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Note que, ao tentar abrir o arquivo com LibreOffice Calc, este é lido como um `csv` e que o charset é \"UTF-16\". Na caixa de pré-visualização dos campos, da primeira imagem, vemos que os dados possuem uma `→` indicando que o separador é uma tabulação. A segunda imagem mostra que, ao selecionar \"Tabulação\" nas \"Opções de separadores\", os dados se organizam. Isso significa que, como desconfiávamos, se trata de outro tipo de formato. Não é novidade que tenhamos que lidar com situações desse tipo quando se trata de dados públicos governamentais. \n","\n","A próxima questão que queremos responder é: podemos carregar o conjunto de dados em um `DataFrame` do `pandas` usando o método `read_csv()` em vez de `read_excel()`? "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"UnicodeError","evalue":"UTF-16 stream does not start with BOM","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mUTF-16\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1681\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype_backend\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[39m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:550\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:639\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/anaconda3/envs/exercicios/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:2021\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mUnicodeError\u001b[0m: UTF-16 stream does not start with BOM"]}],"source":["df_test = pd.read_csv(file, sep=\"\\t\", encoding=\"UTF-16\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Sim, aparentemente é possível, contudo, obtemos um `UnicodeError` que indica um problema no conjunto de caracteres. Tentaremos compreender e solucionar esta exceção em seguida."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Solucionando o problemas do conjunto de caracteres"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["A exceção `\"UnicodeError: UTF-16 stream does not start with BOM` ocorre quando tentamos decodificar um fluxo de bytes, mas o fluxo de bytes não começa com o [BOM (Byte Order Mark)](https://en.wikipedia.org/wiki/Byte_order_mark) necessário. Em outras palavras, o decodificador do `pandas` esperava encontrar o BOM no início do fluxo de bytes UTF-16, mas não o encontrou. Isso geralmente ocorre quando o BOM foi omitido, ou quando o arquivo foi codificado em um formato diferente, mas erroneamente rotulado como UTF-16. Dado o que vimos até aqui, esta última possibilidade é bem plausível. Mas vamos continuar buscando pistas."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Para descobrir o esquema de codificação dos caracteres dos arquivos, vamos usar o utilitário [`enca`](https://linux.die.net/man/1/enca) do UNIX. O `enca` é um utilitário que detecta o conjunto de caracteres e a codificação de arquivos de texto e, também, pode convertê-los em outras codificações usando um conversor embutido ou bibliotecas externas como [libiconv](https://www.gnu.org/software/libiconv/), [librecode](https://ubuntu.pkgs.org/20.04/ubuntu-main-amd64/librecode-dev_3.6-24_amd64.deb.html) ou [cstocs](https://www.venea.net/man/Cz::Cstocs(3pm)).\n","\n","Como meu objetivo é saber apenas o encoding, uso o seguinte comando passando um dos arquivos de dados:"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Universal character set 2 bytes; UCS-2; BMP\n","  LF line terminators\n","  Byte order reversed in pairs (1,2 -> 2,1)\n"]}],"source":["!enca -L none ./data/raw/DadosBO_SP/DadosBO_2023_1\\(ROUBO\\ DE\\ CELULAR\\).xls"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Compreendendo o formato de codificação de caracteres do conjunto de dados"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["A saída indica que o encoding é Universal Character Set de 2 bytes, ou UCS-2. Esse é um formato de codificação de caracteres que representa cada caractere em 2 bytes (16 bits). Os outros elementos da saída são os seguintes:\n","\n","- **BMP** refere-se ao \"[Basic Multilingual Plane](https://en.wikipedia.org/wiki/Plane_(Unicode)#Basic_Multilingual_Plane)\", que é uma parte do conjunto de caracteres Unicode que abrange a maioria dos caracteres comumente usados em várias línguas. \n","- **LF line terminators**, indica que o arquivo usa terminadores de linha **LF (Line Feed)**, que é um caractere de controle para indicar o fim de uma linha de texto. Isso é comum em sistemas baseados em Unix/Linux e é representado pelos caracteres `\\n`. \n","- **Byte order reversed in pairs (1,2 -> 2,1)** significa que a ordem dos bytes é invertida em pares (1, 2 -> 2, 1). \n","\n","Como dito, em UCS-2, cada caractere é representado por dois bytes. A ordem normal de armazenamento desses bytes na memoria seria primeiro o byte de ordem baixa (**Low Order Byte**) e depois o byte de ordem alta (**High Order Byte**). No entanto, com a ordem invertida em pares, os bytes são armazenados de forma reversa, ou seja, o byte de ordem alta vem antes do byte de ordem baixa.\n","\n","Os conceitos de \"Low Order Byte\" (LOB) e \"High Order Byte\" (HOB) estão relacionados à forma como os bytes são organizados na memória em sistemas que utilizam múltiplos bytes para representar informações , como conjuntos de caracteres ou valores numéricos. Eles estão ligados a um conceito mais amplo conhecido como [Codificação de Largura Variável](https://pt.wikipedia.org/wiki/Codifica%C3%A7%C3%A3o_de_largura_vari%C3%A1vel), onde os mais comuns são as codificações multibyte, que usam vários números de bytes (octetos, daí a saída genérica \"application/octet-stream\" do comando `file`) para codificar diferentes caracteres. \n","\n","O LOB é o byte menos significativo em uma sequência de bytes que compõem uma unidade de informação. Em uma codificação de caracteres ou valor numérico, o LOB geralmente carrega a parte menos significativa da informação. Em contrapartida, o HOB é o byte mais significativo em uma sequência de bytes. Ele carrega a parte mais significativa da informação.\n","\n","\"Menos significativa\" e \"mais significativa\" são terminologias relacionadas com a importância relativa de partes individuais de um valor binário (sequência de bits) ao representar informações. Só pra relembrar: \n","- **Bit**: A menor unidade de informação em um sistema binário, podendo ser 0 ou 1.\n","- **Byte**: Um conjunto de 8 bits.\n","- **Sequência de Bytes**: Valores numéricos, caracteres e outros tipos de dados frequentemente representados por sequências de bytes.\n","\n","Quando falamos sobre \"menos significativa\" e \"mais significativa\", estamos nos referindo à posição desses bits e bytes na representação binária de um valor. Essa terminologia se origina do sistema posicional que usamos para representar números, incluindo números decimais e binários.\n","\n","**Exemplo para ficar menos abstrato:**\n","\n","Em um sistema posicional, como o sistema decimal que usamos cotidianamente, o valor de um dígito depende de sua posição. Por exemplo, no número decimal \"314\", o \"3\" na posição das centenas representa uma quantidade significativamente maior do que o \"1\" na posição das dezenas, que é, por sua vez, mais significativo do que o \"4\" na posição das unidades.\n","\n","Em uma representação binária funciona da mesma forma: cada bit, em uma posição específica, tem um valor que é uma potência de 2. Por exemplo, no número binário \"10110\", o bit mais à esquerda (o \"1\" mais significativo) representa 16 (ou $2^4$), enquanto o bit mais à direita (o \"0\" menos significativo) representa 1 (ou $2^0$).\n","\n","Ao falar sobre partes \"mais significativas\" e \"menos significativas\", estamos observando como as posições dos dígitos ou bits contribuem para o valor geral de um número ou caractere. As partes mais significativas têm um impacto maior no valor total, enquanto as partes menos significativas têm um impacto menor.\n","\n","Portanto, se trata de uma maneira de descrever a importância relativa das posições de dígitos ou bits em uma representação numérica ou binária, com base na forma como o sistema posicional funciona. Para ilustrar, imagine que estamos representando o número decimal 314 em uma codificação numérica de 16 bits:\n","\n","```\n","00000001 00111010\n","```\n","Temos 16 bits divididos em dois bytes. A representação binária desse número é \"0000000100111010\". Agora, analisemos essa representação em termos de \"menos significativa\" e \"mais significativa\":\n","\n","**Menos Significativa**: Os bits à direita são considerados menos significativos. No nosso exemplo, \"00111010\" é a parte menos significativa. Alterações nesses bits teriam um impacto menor no valor geral do número.\n","\n","**Mais Significativa**: Os bits à esquerda são considerados mais significativos. No nosso exemplo, \"00000001\" é a parte mais significativa. Alterações nesses bits teriam um impacto maior no valor geral do número.\n","\n","A saída do `enca` informa que a ordem dessas partes é invertida. Isso ocorre, pois a ordem em que os LOBs e HOBs são organizados pode variar entre diferentes sistemas e arquiteturas de computador. Existem dois principais padrões de ordenação:\n","\n","**Little Endian**: Nesse padrão, o LOB é armazenado antes do HOB. Ou seja, o byte de menor valor é armazenado primeiro na memória. Isso é comum em muitos sistemas, incluindo os de arquitetura x86 e x86-64, que são amplamente usados em PCs e laptops.\n","\n","**Big Endian**: Nesse padrão, o HOB é armazenado antes do LOB. O byte de maior valor é armazenado primeiro na memória. Isso é comum em algumas arquiteturas de processadores, como PowerPC e algumas implementações de redes.\n","\n","Esses conceitos são particularmente relevantes ao lidar com codificações de caracteres em que cada caractere é representado por múltiplos bytes (multibyte). A ordem dos bytes pode afetar a forma como os caracteres são interpretados e, portanto, é importante considerar a ordem de bytes correta ao lidar com diferentes sistemas e formatos de dados. É justamente que estamos enfrentando no momento.  "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Importando os dados com a codificação de caracteres correta\n","\n","O UCS-2 é um esquema de codificação mais antigo e mais restrito porque só pode representar os caracteres do BMP, isto é, os caracteres Unicode que podem ser representados em 16 bits. Caracteres fora do BMP não podem ser representados diretamente em UCS-2. Verifiquei na  [documentação do `pandas`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) que a [lista de encodings suportados pelo Python](https://docs.python.org/3/library/codecs.html#standard-encodings) não inclui UCS-2. Por tanto, este é o motivo do `pandas`, não suportar esse encoding.\n","\n","Contudo, o esquema **UTF-16**, uma codificação mais moderna e flexível que pode representar todos os caracteres Unicode, incluindo aqueles fora do BMP, também representa caracteres em 2 bytes e é suportada pela linguagem. Por que o `pandas` não foi capaz de carregar os dados mesmo assim? A resposta é simples: precisamos informar o decodificador do `pandas` que a ordem dos bytes está invertida, ou seja, precisamos indicar o padrão **Little Endian**, ou **\"LE\"**, para que a biblioteca consiga ler os bytes na ordem correta: "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["df_test = pd.read_csv(file, sep=\"\\t\", encoding=\"UTF-16 LE\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ANO_BO</th>\n","      <th>NUM_BO</th>\n","      <th>NUMERO_BOLETIM</th>\n","      <th>BO_INICIADO</th>\n","      <th>BO_EMITIDO</th>\n","      <th>DATAOCORRENCIA</th>\n","      <th>HORAOCORRENCIA</th>\n","      <th>PERIDOOCORRENCIA</th>\n","      <th>DATACOMUNICACAO</th>\n","      <th>DATAELABORACAO</th>\n","      <th>...</th>\n","      <th>PLACA_VEICULO</th>\n","      <th>UF_VEICULO</th>\n","      <th>CIDADE_VEICULO</th>\n","      <th>DESCR_COR_VEICULO</th>\n","      <th>DESCR_MARCA_VEICULO</th>\n","      <th>ANO_FABRICACAO</th>\n","      <th>ANO_MODELO</th>\n","      <th>DESCR_TIPO_VEICULO</th>\n","      <th>QUANT_CELULAR</th>\n","      <th>MARCA_CELULAR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023</td>\n","      <td>2059</td>\n","      <td>2059/2023</td>\n","      <td>01/01/2023 00:08:34</td>\n","      <td>01/01/2023 00:08:34</td>\n","      <td>29/12/2022</td>\n","      <td>NaN</td>\n","      <td>A NOITE</td>\n","      <td>30/12/2022</td>\n","      <td>01/01/2023 00:08:34</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>Xiaomi</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023</td>\n","      <td>27</td>\n","      <td>27/2023</td>\n","      <td>01/01/2023 00:39:51</td>\n","      <td>01/01/2023 00:39:51</td>\n","      <td>31/12/2022</td>\n","      <td>23:32</td>\n","      <td>A NOITE</td>\n","      <td>01/01/2023</td>\n","      <td>01/01/2023 00:39:51</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>Apple</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2023</td>\n","      <td>8583</td>\n","      <td>8583/2023</td>\n","      <td>01/01/2023 00:47:10</td>\n","      <td>01/01/2023 00:47:12</td>\n","      <td>30/01/2022</td>\n","      <td>23:20</td>\n","      <td>A NOITE</td>\n","      <td>31/12/2022</td>\n","      <td>01/01/2023 00:47:10</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>Apple</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2023</td>\n","      <td>8584</td>\n","      <td>8584/2023</td>\n","      <td>01/01/2023 00:47:35</td>\n","      <td>01/01/2023 00:47:38</td>\n","      <td>30/12/2022</td>\n","      <td>22:05</td>\n","      <td>A NOITE</td>\n","      <td>31/12/2022</td>\n","      <td>01/01/2023 00:47:35</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>Apple</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2023</td>\n","      <td>8588</td>\n","      <td>8588/2023</td>\n","      <td>01/01/2023 00:48:47</td>\n","      <td>01/01/2023 00:48:49</td>\n","      <td>30/12/2022</td>\n","      <td>20:30</td>\n","      <td>A NOITE</td>\n","      <td>31/12/2022</td>\n","      <td>01/01/2023 00:48:47</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>Xiaomi</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 54 columns</p>\n","</div>"],"text/plain":["   ANO_BO  NUM_BO NUMERO_BOLETIM          BO_INICIADO           BO_EMITIDO  \\\n","0    2023    2059      2059/2023  01/01/2023 00:08:34  01/01/2023 00:08:34   \n","1    2023      27        27/2023  01/01/2023 00:39:51  01/01/2023 00:39:51   \n","2    2023    8583      8583/2023  01/01/2023 00:47:10  01/01/2023 00:47:12   \n","3    2023    8584      8584/2023  01/01/2023 00:47:35  01/01/2023 00:47:38   \n","4    2023    8588      8588/2023  01/01/2023 00:48:47  01/01/2023 00:48:49   \n","\n","  DATAOCORRENCIA HORAOCORRENCIA PERIDOOCORRENCIA DATACOMUNICACAO  \\\n","0     29/12/2022            NaN          A NOITE      30/12/2022   \n","1     31/12/2022          23:32          A NOITE      01/01/2023   \n","2     30/01/2022          23:20          A NOITE      31/12/2022   \n","3     30/12/2022          22:05          A NOITE      31/12/2022   \n","4     30/12/2022          20:30          A NOITE      31/12/2022   \n","\n","        DATAELABORACAO  ... PLACA_VEICULO UF_VEICULO CIDADE_VEICULO  \\\n","0  01/01/2023 00:08:34  ...           NaN        NaN            NaN   \n","1  01/01/2023 00:39:51  ...           NaN        NaN            NaN   \n","2  01/01/2023 00:47:10  ...           NaN        NaN            NaN   \n","3  01/01/2023 00:47:35  ...           NaN        NaN            NaN   \n","4  01/01/2023 00:48:47  ...           NaN        NaN            NaN   \n","\n","  DESCR_COR_VEICULO  DESCR_MARCA_VEICULO ANO_FABRICACAO ANO_MODELO  \\\n","0               NaN                  NaN            0.0        0.0   \n","1               NaN                  NaN            0.0        0.0   \n","2               NaN                  NaN            0.0        0.0   \n","3               NaN                  NaN            0.0        0.0   \n","4               NaN                  NaN            0.0        0.0   \n","\n","  DESCR_TIPO_VEICULO QUANT_CELULAR MARCA_CELULAR  \n","0                NaN           1.0        Xiaomi  \n","1                NaN           1.0         Apple  \n","2                NaN           1.0         Apple  \n","3                NaN           1.0         Apple  \n","4                NaN           1.0        Xiaomi  \n","\n","[5 rows x 54 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_test.head()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Padronizando o nome dos arquivos e importando os dados no Pandas"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Agora que desvendamos a natureza dos arquivos de dados fornecidos pelo governo, vamos realizar as tarefas de transformar o nome dos arquivos para um padrão seguro e, finalmente, importar os datasets como o encoding correto para gerar um `DataFrame` e prosseguir para a etapa: [Processamento dos Dados](\"./04_processamento_dos_dados.ipynb\"),  que tornará os dados úteis para análise exploratória. "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["O script a seguir, busca resolver ambos os problemas, padronizando o nome dos arquivos para \"DadosBO_{ano}_{nome_do_mês}, e realizando a leitura correta dos bytes gerando um DataFrame no qual podemos começar a trabalhar:"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import os\n","import shutil\n","import re"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_728800/2381841722.py:46: DtypeWarning: Columns (31,32,37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n","  datasets = [pd.read_csv(file, sep='\\t', encoding=\"UTF-16 LE\")\n","/tmp/ipykernel_728800/2381841722.py:46: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n","  datasets = [pd.read_csv(file, sep='\\t', encoding=\"UTF-16 LE\")\n","/tmp/ipykernel_728800/2381841722.py:46: DtypeWarning: Columns (31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n","  datasets = [pd.read_csv(file, sep='\\t', encoding=\"UTF-16 LE\")\n"]}],"source":["input_dir = \"data/raw/DadosBO_SP/\"\n","output_dir = \"data/processed/DadosBO_SP/\"\n","\n","os.makedirs(output_dir, exist_ok=True)\n","\n","MONTHS = {\n","    \"1\": \"Janeiro\",\n","    \"2\": \"Fevereiro\",\n","    \"3\": \"Março\",\n","    \"4\": \"Abril\",\n","    \"5\": \"Maio\",\n","    \"6\": \"Junho\",\n","    \"7\": \"Julho\",\n","    \"8\": \"Agosto\",\n","    \"9\": \"Setembro\",\n","    \"10\": \"Outubro\",\n","    \"11\": \"Novembro\",\n","    \"12\": \"Dezembro\"\n","}\n","\n","pattern = re.compile(r\"(\\d+)\\(ROUBO DE CELULAR\\)\")\n","\n","\n","def process_file(input_dir, output_dir):\n","    for filename in os.listdir(input_dir):\n","\n","        if filename.endswith(\".xls\"):\n","            match = pattern.search(filename)\n","\n","            if match:\n","                num_month = match.group(1)\n","                name_month = MONTHS.get(num_month, num_month)\n","\n","                new_name = pattern.sub(f\"{name_month}\", filename)\n","\n","                old_path = os.path.join(input_dir, filename)\n","                new_path = os.path.join(output_dir, new_name)\n","\n","                shutil.copy(old_path, new_path)\n","\n","                yield new_path\n","\n","\n","file_path_generator = process_file(input_dir, output_dir)\n","\n","datasets = [pd.read_csv(file, sep='\\t', encoding=\"UTF-16 LE\")\n","            for file in file_path_generator]\n","\n","df = pd.concat(datasets, axis=0, ignore_index=True)\n","\n","pd.set_option(\"display.max_columns\", None)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["(119158, 54)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 119158 entries, 0 to 119157\n","Data columns (total 54 columns):\n"," #   Column                    Non-Null Count   Dtype  \n","---  ------                    --------------   -----  \n"," 0   ANO_BO                    119158 non-null  int64  \n"," 1   NUM_BO                    119158 non-null  int64  \n"," 2   NUMERO_BOLETIM            119158 non-null  object \n"," 3   BO_INICIADO               119158 non-null  object \n"," 4   BO_EMITIDO                119158 non-null  object \n"," 5   DATAOCORRENCIA            119158 non-null  object \n"," 6   HORAOCORRENCIA            110412 non-null  object \n"," 7   PERIDOOCORRENCIA          119158 non-null  object \n"," 8   DATACOMUNICACAO           119158 non-null  object \n"," 9   DATAELABORACAO            119158 non-null  object \n"," 10  BO_AUTORIA                119158 non-null  object \n"," 11  FLAGRANTE                 119158 non-null  object \n"," 12  NUMERO_BOLETIM_PRINCIPAL  37625 non-null   object \n"," 13  LOGRADOURO                111762 non-null  object \n"," 14  NUMERO                    118915 non-null  float64\n"," 15  BAIRRO                    117337 non-null  object \n"," 16  CIDADE                    118915 non-null  object \n"," 17  UF                        118915 non-null  object \n"," 18  LATITUDE                  102955 non-null  object \n"," 19  LONGITUDE                 102955 non-null  object \n"," 20  DESCRICAOLOCAL            119158 non-null  object \n"," 21  EXAME                     0 non-null       float64\n"," 22  SOLUCAO                   119158 non-null  object \n"," 23  DELEGACIA_NOME            119158 non-null  object \n"," 24  DELEGACIA_CIRCUNSCRICAO   119158 non-null  object \n"," 25  ESPECIE                   119158 non-null  object \n"," 26  RUBRICA                   119158 non-null  object \n"," 27  DESDOBRAMENTO             201 non-null     object \n"," 28  STATUS                    119158 non-null  object \n"," 29  TIPOPESSOA                378 non-null     object \n"," 30  VITIMAFATAL               378 non-null     object \n"," 31  NATURALIDADE              8 non-null       object \n"," 32  NACIONALIDADE             27 non-null      object \n"," 33  SEXO                      377 non-null     object \n"," 34  DATANASCIMENTO            342 non-null     object \n"," 35  IDADE                     342 non-null     float64\n"," 36  ESTADOCIVIL               146 non-null     object \n"," 37  PROFISSAO                 117 non-null     object \n"," 38  GRAUINSTRUCAO             61 non-null      object \n"," 39  CORCUTIS                  0 non-null       float64\n"," 40  NATUREZAVINCULADA         378 non-null     object \n"," 41  TIPOVINCULO               378 non-null     object \n"," 42  RELACIONAMENTO            0 non-null       float64\n"," 43  PARENTESCO                0 non-null       float64\n"," 44  PLACA_VEICULO             27064 non-null   object \n"," 45  UF_VEICULO                26980 non-null   object \n"," 46  CIDADE_VEICULO            26980 non-null   object \n"," 47  DESCR_COR_VEICULO         27041 non-null   object \n"," 48  DESCR_MARCA_VEICULO       27068 non-null   object \n"," 49  ANO_FABRICACAO            118603 non-null  float64\n"," 50  ANO_MODELO                115630 non-null  float64\n"," 51  DESCR_TIPO_VEICULO        27037 non-null   object \n"," 52  QUANT_CELULAR             119031 non-null  float64\n"," 53  MARCA_CELULAR             119032 non-null  object \n","dtypes: float64(9), int64(2), object(43)\n","memory usage: 49.1+ MB\n"]}],"source":["df.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["et voilà!\n","\n","---"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Referências\n","- [Microsoft - BOF (Beginning of File)](https://learn.microsoft.com/en-us/openspecs/office_file_formats/ms-xls/4d6a3d1e-d7c5-405f-bbae-d01e9cb79366)\n","- [Wikipedia - BOM (Byte Order Mark)](https://en.wikipedia.org/wiki/Byte_order_mark)\n","- [Wikipedia - BPM (Basic Multilingual Plane)](https://en.wikipedia.org/wiki/Plane_(Unicode)#Basic_Multilingual_Plane)\n","- [Wikipedia - MIME (Multipurpose Internet Mail Extensions)](https://en.wikipedia.org/wiki/MIME)\n","- [Wikipedia - Codificação de Largura Variável](https://pt.wikipedia.org/wiki/Codifica%C3%A7%C3%A3o_de_largura_vari%C3%A1vel)\n","- [Unicode Consortium - Glossary](https://www.unicode.org/glossary/)\n","- [UTF-8 and Unicode FAQ for Unix/Linux](https://www.cl.cam.ac.uk/~mgk25/unicode.html)\n","- [Wikipedia - Universal Character Set](https://en.wikipedia.org/wiki/Universal_Coded_Character_Set)\n","- [Wikipedia - UTF-16](https://en.wikipedia.org/wiki/UTF-16)\n","- [Wikipedia - Endianness](https://en.wikipedia.org/wiki/Endianness)\n","- [Documentação Pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n","- [Documentação Python](https://docs.python.org/3/library/codecs.html#standard-encodings)"]}],"metadata":{"kernelspec":{"display_name":"geospace","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
